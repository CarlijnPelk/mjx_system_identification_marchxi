{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///media/carlijn/500GB/mjx_sysid-main\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: sysidmjx\n",
      "  Building editable for sysidmjx (pyproject.toml): started\n",
      "  Building editable for sysidmjx (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for sysidmjx: filename=sysidmjx-0.1.0-0.editable-py3-none-any.whl size=3653 sha256=7a23abae51d2f505947a87f5db4c0f86e825de0efa31eebb40d56811ee848c4d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-66i24uil/wheels/b3/99/b6/98b73b7b9fbacb21729f0760aa16bc8c3defe7f5d5403468ed\n",
      "Successfully built sysidmjx\n",
      "Installing collected packages: sysidmjx\n",
      "  Attempting uninstall: sysidmjx\n",
      "    Found existing installation: sysidmjx 0.1.0\n",
      "    Uninstalling sysidmjx-0.1.0:\n",
      "      Successfully uninstalled sysidmjx-0.1.0\n",
      "Successfully installed sysidmjx-0.1.0\n",
      "\n",
      "✓ sysidmjx installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install the sysidmjx package in editable mode\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Install the package\n",
    "result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \"/media/carlijn/500GB/mjx_sysid-main\"], \n",
    "                       capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.returncode != 0:\n",
    "    print(\"STDERR:\", result.stderr)\n",
    "else:\n",
    "    print(\"✓ sysidmjx installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoskeleton System Identification\n",
    "\n",
    "This notebook optimizes physical parameters (armature, friction loss, damping) for all 10 actuated joints of the March exoskeleton.\n",
    "\n",
    "## ⚠️ CRITICAL: Execution Order\n",
    "\n",
    "**RESTART KERNEL, then run cells in this exact order:**\n",
    "\n",
    "1. **Cell 2**: Imports and configuration\n",
    "2. **Cell 4**: Define data loading function (does NOT load data yet)\n",
    "3. **Cell 8**: Model setup - Updates JOINT_NAMES and loads data automatically\n",
    "4. **Cell 10**: Parameter setup - Creates PID gains and optimization functions\n",
    "5. **Cell 12**: Training loop\n",
    "\n",
    "**The key fix:** Cell 8 now loads the model first, updates `JOINT_NAMES` to match the model's actuator order, THEN loads the data. This ensures the data columns are reordered to match the model's internal joint order.\n",
    "\n",
    "## Data Requirements\n",
    "\n",
    "Your CSV file should have the following columns:\n",
    "- `timestamp`: Time in seconds\n",
    "- For each joint in `[left_hip_aa, left_hip_fe, left_knee, left_ankle_dpf, left_ankle_ie, right_hip_aa, right_hip_fe, right_knee, right_ankle_dpf, right_ankle_ie]`:\n",
    "  - `<joint_name>_pos`: Joint position (radians)\n",
    "  - `<joint_name>_vel`: Joint velocity (rad/s)\n",
    "  - `<joint_name>_ctrl`: Control input (desired position in radians, or current in Amps - will be converted)\n",
    "\n",
    "Example CSV structure:\n",
    "```\n",
    "timestamp,left_hip_aa_pos,left_hip_aa_vel,left_hip_aa_ctrl,left_hip_fe_pos,...\n",
    "0.000,0.1,0.0,0.15,0.2,...\n",
    "0.001,0.101,0.1,0.15,0.21,...\n",
    "```\n",
    "\n",
    "## PID Gains Used\n",
    "The optimization uses the following PID gains from your system:\n",
    "- **Ankle DPF**: P=50, I=0, D=0.2\n",
    "- **Hip AA**: P=80, I=0, D=0.4  \n",
    "- **Hip FE**: P=120, I=0, D=0.8\n",
    "- **Knee**: P=80, I=0, D=0.6\n",
    "- **Ankle IE (Linear)**: P=3.0, I=0, D=0.03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sysidmjx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msysidmjx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_loss_train_functions, get_batch\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m     18\u001b[39m config.update(\u001b[33m\"\u001b[39m\u001b[33mjax_debug_nans\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sysidmjx'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['JAX_PLATFORMS'] = 'cpu'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "from typing import Callable, Dict\n",
    "from jax import Array\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sysidmjx.core import generate_loss_train_functions, get_batch\n",
    "from jax import config\n",
    "\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_default_matmul_precision\", \"high\")\n",
    "\n",
    "\n",
    "class PARAMS:\n",
    "    SEED = jax.random.PRNGKey(2)\n",
    "    EXPERIMENT_NAME = \"exo_optimization\"\n",
    "\n",
    "    class DATASET:\n",
    "        PATH = \"assets/exo/dataset/exo_data_1627.csv\"  # Your exo data file\n",
    "        DT = 0.001  # Adjust to your data sampling rate\n",
    "        \n",
    "    class SIM:\n",
    "        PATH = \"assets/exo/model/exo_hydrax.xml\"\n",
    "        INTEGRATOR = mujoco.mjtIntegrator.mjINT_EULER\n",
    "        ITERATIONS = 1\n",
    "\n",
    "    class TRAIN:\n",
    "        EPOCH_NUM = 100\n",
    "        BATCH_SIZE = 100  # Adjust based on your data size\n",
    "        LEARNING_RATE = 1e-3\n",
    "        TX = optax.adam(LEARNING_RATE)\n",
    "\n",
    "# Joint names in your exoskeleton (excluding the free joint for safety catcher)\n",
    "JOINT_NAMES = [\n",
    "    'left_hip_aa', 'left_hip_fe', 'left_knee', \n",
    "    'left_ankle_dpf', 'left_ankle_ie',\n",
    "    'right_hip_aa', 'right_hip_fe', 'right_knee',\n",
    "    'right_ankle_dpf', 'right_ankle_ie'\n",
    "]\n",
    "\n",
    "# PID gains for each joint (P, I, D)\n",
    "PID_GAINS = {\n",
    "    'left_ankle_dpf': (50, 0, 0.2),\n",
    "    'right_ankle_dpf': (50, 0, 0.2),\n",
    "    'left_hip_aa': (80, 0, 0.4),\n",
    "    'right_hip_aa': (80, 0, 0.4),\n",
    "    'left_hip_fe': (120, 0, 0.8),\n",
    "    'right_hip_fe': (120, 0, 0.8),\n",
    "    'left_knee': (80, 0, 0.6),\n",
    "    'right_knee': (80, 0, 0.6),\n",
    "    'left_ankle_ie': (3.0, 0, 0.03),  # Linear actuators\n",
    "    'right_ankle_ie': (3.0, 0, 0.03),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare exoskeleton data\n",
    "\n",
    "This cell loads your exoskeleton data. Your CSV should have columns for:\n",
    "- Time stamps\n",
    "- Joint positions for all 10 joints\n",
    "- Joint velocities for all 10 joints  \n",
    "- Control inputs (currents or desired positions) for all 10 joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_exo_data(csv_path):\n",
    "    \"\"\"\n",
    "    Load exoskeleton data from CSV and reorder to match model actuator order.\n",
    "    \n",
    "    Expected CSV columns:\n",
    "    - timestamp\n",
    "    - For each joint: <joint_name>_pos, <joint_name>_vel, <joint_name>_ctrl\n",
    "    \n",
    "    IMPORTANT: The data will be reordered to match JOINT_NAMES (which reflects the model's actuator order)\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"CSV loaded: {len(df)} samples, {len(df.columns)} columns\")\n",
    "    print(f\"Available columns: {list(df.columns)[:10]}...\")  # Show first 10\n",
    "    \n",
    "    # Extract data for all joints IN THE ORDER SPECIFIED BY JOINT_NAMES\n",
    "    n_samples = len(df)\n",
    "    n_joints = len(JOINT_NAMES)\n",
    "    \n",
    "    qpos = np.zeros((n_samples, n_joints))\n",
    "    qvel = np.zeros((n_samples, n_joints))\n",
    "    qctrl = np.zeros((n_samples, n_joints))\n",
    "    \n",
    "    print(f\"\\nLoading data for {n_joints} joints in MODEL ORDER:\")\n",
    "    print(f\"JOINT_NAMES (model actuator order): {JOINT_NAMES}\")\n",
    "    missing_cols = []\n",
    "    \n",
    "    for i, joint in enumerate(JOINT_NAMES):\n",
    "        pos_col = f'{joint}_pos'\n",
    "        vel_col = f'{joint}_vel'\n",
    "        ctrl_col = f'{joint}_ctrl'\n",
    "        \n",
    "        print(f\"  [{i}] {joint}:\", end=\" \")\n",
    "        \n",
    "        if pos_col not in df.columns:\n",
    "            missing_cols.append(pos_col)\n",
    "            print(f\"✗ MISSING {pos_col}\")\n",
    "        else:\n",
    "            qpos[:, i] = df[pos_col].values\n",
    "            \n",
    "        if vel_col not in df.columns:\n",
    "            missing_cols.append(vel_col)\n",
    "            print(f\"✗ MISSING {vel_col}\")\n",
    "        else:\n",
    "            qvel[:, i] = df[vel_col].values\n",
    "            \n",
    "        if ctrl_col not in df.columns:\n",
    "            missing_cols.append(ctrl_col)\n",
    "            print(f\"✗ MISSING {ctrl_col}\")\n",
    "        else:\n",
    "            qctrl[:, i] = df[ctrl_col].values\n",
    "            \n",
    "        if pos_col in df.columns and vel_col in df.columns and ctrl_col in df.columns:\n",
    "            print(f\"✓\")\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"\\n⚠️  ERROR: Missing columns in CSV: {missing_cols[:5]}...\")\n",
    "        print(f\"Total missing: {len(missing_cols)} columns\")\n",
    "        raise ValueError(f\"CSV file is missing required columns. First few: {missing_cols[:5]}\")\n",
    "    \n",
    "    print(f\"\\n✓ Successfully loaded and reordered data for all {n_joints} joints\")\n",
    "    \n",
    "    # Create next timestep targets\n",
    "    qpos_next = np.roll(qpos, -1, axis=0)\n",
    "    qpos_next[-1] = qpos[-1]  # Last sample\n",
    "    \n",
    "    dataset = {\n",
    "        'qpos': jnp.array(qpos),\n",
    "        'qvel': jnp.array(qvel),\n",
    "        'qact': jnp.array(qctrl),\n",
    "        'qpos_next': jnp.array(qpos_next)\n",
    "    }\n",
    "    \n",
    "    print(f\"Dataset shapes: qpos={dataset['qpos'].shape}, qvel={dataset['qvel'].shape}, qact={dataset['qact'].shape}\")\n",
    "    \n",
    "    return dataset, df\n",
    "\n",
    "print(\"✓ Data loading function defined. DO NOT RUN THIS CELL UNTIL AFTER MODEL SETUP!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with synthetic data (optional)\n",
    "\n",
    "Before using real data, you can test the pipeline with synthetic data generated from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_synthetic_test_data(n_samples=1000):\n",
    "#     \"\"\"\n",
    "#     Generate synthetic data to test the optimization pipeline.\n",
    "#     This simulates simple sinusoidal joint movements.\n",
    "    \n",
    "#     NOTE: Call this AFTER running the model setup cell so JOINT_NAMES is correctly populated.\n",
    "#     \"\"\"\n",
    "#     dt = 0.001\n",
    "#     t = np.arange(n_samples) * dt\n",
    "    \n",
    "#     n_joints = len(JOINT_NAMES)\n",
    "#     qpos = np.zeros((n_samples, n_joints))\n",
    "#     qvel = np.zeros((n_samples, n_joints))\n",
    "#     qctrl = np.zeros((n_samples, n_joints))\n",
    "    \n",
    "#     # Generate sinusoidal trajectories for each joint\n",
    "#     for i in range(n_joints):\n",
    "#         amplitude = 0.2 + 0.1 * i  # Different amplitudes\n",
    "#         frequency = 0.5 + 0.1 * i   # Different frequencies\n",
    "#         phase = i * np.pi / n_joints\n",
    "        \n",
    "#         qpos[:, i] = amplitude * np.sin(2 * np.pi * frequency * t + phase)\n",
    "#         qvel[:, i] = amplitude * 2 * np.pi * frequency * np.cos(2 * np.pi * frequency * t + phase)\n",
    "#         qctrl[:, i] = qpos[:, i]  # Perfect tracking for testing\n",
    "    \n",
    "#     # Create next timestep\n",
    "#     qpos_next = np.roll(qpos, -1, axis=0)\n",
    "#     qpos_next[-1] = qpos[-1]\n",
    "    \n",
    "#     dataset = {\n",
    "#         'qpos': jnp.array(qpos),\n",
    "#         'qvel': jnp.array(qvel),\n",
    "#         'qact': jnp.array(qctrl),\n",
    "#         'qpos_next': jnp.array(qpos_next)\n",
    "#     }\n",
    "    \n",
    "#     # Create dataframe for visualization\n",
    "#     df_data = {'timestamp': t}\n",
    "#     for i, joint in enumerate(JOINT_NAMES):\n",
    "#         df_data[f'{joint}_pos'] = qpos[:, i]\n",
    "#         df_data[f'{joint}_vel'] = qvel[:, i]\n",
    "#         df_data[f'{joint}_ctrl'] = qctrl[:, i]\n",
    "#     df = pd.DataFrame(df_data)\n",
    "    \n",
    "#     print(f\"Generated {n_samples} synthetic data samples for {n_joints} joints\")\n",
    "#     print(f\"Data shape: qpos={dataset['qpos'].shape}, qvel={dataset['qvel'].shape}\")\n",
    "#     print(f\"Joints: {JOINT_NAMES}\")\n",
    "    \n",
    "#     return dataset, df\n",
    "\n",
    "# # Use synthetic data for testing:\n",
    "# dataset, df = generate_synthetic_test_data(n_samples=500)\n",
    "# print(\"\\n✓ Synthetic test data generated. You can now run the optimization cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mj_model = mujoco.MjModel.from_xml_path(PARAMS.SIM.PATH)\n",
    "mj_model.opt.timestep = PARAMS.DATASET.DT\n",
    "mj_model.opt.iterations = PARAMS.SIM.ITERATIONS\n",
    "mj_model.opt.integrator = PARAMS.SIM.INTEGRATOR\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "# Print model info\n",
    "print(f\"integrator: {mj_model.opt.integrator}\")\n",
    "print(f\"timestep: {mj_model.opt.timestep}\")\n",
    "print(f\"iterations: {mj_model.opt.iterations}\")\n",
    "print(f\"Number of DOF: {mj_model.nv}\")\n",
    "print(f\"Number of actuators: {mj_model.nu}\")\n",
    "\n",
    "# Get actual actuator names from model (this is the TRUE order!)\n",
    "model_actuators = [mujoco.mj_id2name(mj_model, mujoco.mjtObj.mjOBJ_ACTUATOR, i) for i in range(mj_model.nu)]\n",
    "print(f\"Actuators (MODEL ORDER): {model_actuators}\")\n",
    "\n",
    "# CRITICAL: Update JOINT_NAMES to match the model's actuator order!\n",
    "print(f\"\\n⚠️  IMPORTANT: Updating JOINT_NAMES to match model actuator order\")\n",
    "print(f\"Old JOINT_NAMES: {JOINT_NAMES}\")\n",
    "JOINT_NAMES.clear()\n",
    "JOINT_NAMES.extend(model_actuators)\n",
    "print(f\"New JOINT_NAMES: {JOINT_NAMES}\")\n",
    "\n",
    "# Verify all joints exist\n",
    "print(f\"\\nVerifying joints in model:\")\n",
    "for joint_name in JOINT_NAMES:\n",
    "    try:\n",
    "        jnt_id = mujoco.mj_name2id(mj_model, mujoco.mjtObj.mjOBJ_JOINT, joint_name)\n",
    "        print(f\"  ✓ {joint_name}: ID={jnt_id}\")\n",
    "    except:\n",
    "        print(f\"  ✗ {joint_name}: NOT FOUND in model\")\n",
    "\n",
    "mjx_model = mjx.put_model(mj_model)\n",
    "mjx_data = mjx.put_data(mj_model, mj_data)\n",
    "\n",
    "print(f\"\\n✓ Model setup complete!\")\n",
    "print(f\"⚠️  NOW load the data by running: dataset, df = load_exo_data(PARAMS.DATASET.PATH)\")\n",
    "\n",
    "# Load data with corrected JOINT_NAMES\n",
    "dataset, df = load_exo_data(PARAMS.DATASET.PATH)\n",
    "print(f\"\\n✓ Data loaded and reordered to match model actuator order!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify parameters and function they use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random keys for initialization\n",
    "n_joints = len(JOINT_NAMES)\n",
    "keys = jax.random.split(PARAMS.SEED, num=n_joints + 2)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"OPTIMIZATION SETUP\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Number of joints to optimize: {n_joints}\")\n",
    "print(f\"Joint names: {JOINT_NAMES}\")\n",
    "\n",
    "# Define initial parameters for all joints (set to zeros for baseline)\n",
    "zero_params = {\n",
    "    \"armature\": jnp.zeros(n_joints),\n",
    "    \"frictionloss\": jnp.zeros(n_joints),\n",
    "    \"damping\": jnp.zeros(n_joints),\n",
    "}\n",
    "\n",
    "# Define parameters for model initialization, randomly sampled within specific ranges\n",
    "# Note: These are per-joint parameters\n",
    "init_params = {\n",
    "    \"armature\": jax.random.uniform(keys[0], minval=0.0, maxval=5.0, shape=(n_joints,)),\n",
    "    \"frictionloss\": jax.random.uniform(keys[1], minval=0.0, maxval=10.0, shape=(n_joints,)),\n",
    "    \"damping\": jax.random.uniform(keys[2], minval=0.0, maxval=5.0, shape=(n_joints,)),\n",
    "}\n",
    "\n",
    "print(f\"\\nInitial parameter values:\")\n",
    "print(f\"  armature: {init_params['armature']}\")\n",
    "print(f\"  frictionloss: {init_params['frictionloss']}\")\n",
    "print(f\"  damping: {init_params['damping']}\")\n",
    "\n",
    "# Determine the DOF offset (number of DOFs before the actuated joints)\n",
    "# This is typically 0 for models without free joints, or 6 for models with a free joint\n",
    "n_dof_total = mjx_model.nv\n",
    "n_actuated_dof = n_joints\n",
    "dof_offset = n_dof_total - n_actuated_dof\n",
    "print(f\"\\nModel DOF structure:\")\n",
    "print(f\"  Total DOF: {n_dof_total}\")\n",
    "print(f\"  Actuated DOF: {n_actuated_dof}\")\n",
    "print(f\"  DOF offset: {dof_offset}\")\n",
    "\n",
    "# Build PID gains array matching actual joints\n",
    "print(f\"\\nPID Gains for each joint:\")\n",
    "kp_list = []\n",
    "ki_list = []\n",
    "kd_list = []\n",
    "for joint in JOINT_NAMES:\n",
    "    if joint in PID_GAINS:\n",
    "        p, i, d = PID_GAINS[joint]\n",
    "        kp_list.append(p)\n",
    "        ki_list.append(i)\n",
    "        kd_list.append(d)\n",
    "        print(f\"  {joint}: P={p}, I={i}, D={d}\")\n",
    "    else:\n",
    "        print(f\"  ⚠️  {joint}: No PID gains defined, using default (P=50, I=0, D=0.5)\")\n",
    "        kp_list.append(50.0)\n",
    "        ki_list.append(0.0)\n",
    "        kd_list.append(0.5)\n",
    "\n",
    "# Convert to JAX arrays for use in make_action\n",
    "KP_ARRAY = jnp.array(kp_list)\n",
    "KD_ARRAY = jnp.array(kd_list)\n",
    "KI_ARRAY = jnp.array(ki_list)\n",
    "\n",
    "# Verification: Check shapes match\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SHAPE VERIFICATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"KP_ARRAY shape: {KP_ARRAY.shape}\")\n",
    "print(f\"KD_ARRAY shape: {KD_ARRAY.shape}\")\n",
    "print(f\"Dataset qpos shape: {dataset['qpos'].shape}\")\n",
    "print(f\"Dataset qvel shape: {dataset['qvel'].shape}\")\n",
    "print(f\"DOF offset: {dof_offset}\")\n",
    "print(f\"Expected actuated DOF after slicing [dof_offset:]: {n_dof_total - dof_offset}\")\n",
    "print(f\"✓ All shapes should match: {n_joints}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def change_model(params: Dict, old_model: mjx.Model):\n",
    "    \"\"\"\n",
    "    Modify the exoskeleton model by updating physical parameters for all joints.\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionary with 'armature', 'frictionloss', 'damping' arrays (one value per joint)\n",
    "        old_model: The MJX model to update\n",
    "    \n",
    "    Returns:\n",
    "        changed_model: Updated model with new parameters\n",
    "    \"\"\"\n",
    "    # Create full parameter arrays with zeros for any non-actuated DOFs\n",
    "    if dof_offset > 0:\n",
    "        full_armature = jnp.concatenate([jnp.zeros(dof_offset), jnp.abs(params[\"armature\"])])\n",
    "        full_frictionloss = jnp.concatenate([jnp.zeros(dof_offset), jnp.abs(params[\"frictionloss\"])])\n",
    "        full_damping = jnp.concatenate([jnp.zeros(dof_offset), jnp.abs(params[\"damping\"])])\n",
    "    else:\n",
    "        full_armature = jnp.abs(params[\"armature\"])\n",
    "        full_frictionloss = jnp.abs(params[\"frictionloss\"])\n",
    "        full_damping = jnp.abs(params[\"damping\"])\n",
    "    \n",
    "    changed_model = old_model.replace(\n",
    "        dof_armature=full_armature,\n",
    "        dof_frictionloss=full_frictionloss,\n",
    "        dof_damping=full_damping,\n",
    "    )\n",
    "    \n",
    "    return changed_model\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def make_action(params: Dict, data: mjx.Data, ctrl: Array):\n",
    "    \"\"\"\n",
    "    Computes control actions (torques) using PID control law for all joints.\n",
    "    \n",
    "    Args:\n",
    "        params: Model parameters (not used in this controller, but kept for interface)\n",
    "        data: Current state (qpos, qvel)\n",
    "        ctrl: Desired positions for all joints\n",
    "    \n",
    "    Returns:\n",
    "        tau: Control torques for all actuated joints\n",
    "    \"\"\"\n",
    "    # Extract actuated joint positions and velocities (skip any non-actuated DOFs)\n",
    "    qpos_actuated = data.qpos[dof_offset:]\n",
    "    qvel_actuated = data.qvel[dof_offset:]\n",
    "    \n",
    "    # PD control (ignoring integral term for now)\n",
    "    position_error = ctrl - qpos_actuated\n",
    "    tau = KP_ARRAY * position_error - KD_ARRAY * qvel_actuated\n",
    "    \n",
    "    return tau\n",
    "\n",
    "\n",
    "# Generate total loss and training step functions\n",
    "total_loss, train_step, _ = generate_loss_train_functions(\n",
    "    mjx_model=mjx_model,\n",
    "    mjx_data=mjx_data,\n",
    "    change_model=change_model,\n",
    "    make_action=make_action,\n",
    ")\n",
    "\n",
    "print(\"✓ Optimization functions generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training state\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=None,\n",
    "    params=init_params,\n",
    "    tx=PARAMS.TRAIN.TX,\n",
    ")\n",
    "\n",
    "loss_hist = []\n",
    "params_hist = []\n",
    "indxs = jax.numpy.array(range(dataset[\"qpos\"].shape[0]))\n",
    "\n",
    "print(f\"Starting training for {PARAMS.TRAIN.EPOCH_NUM} epochs...\")\n",
    "print(f\"Dataset size: {dataset['qpos'].shape[0]} samples\")\n",
    "print(f\"Batch size: {PARAMS.TRAIN.BATCH_SIZE}\")\n",
    "\n",
    "for epoch in range(PARAMS.TRAIN.EPOCH_NUM):\n",
    "    # VALIDATE - compute loss on full dataset\n",
    "    loss = total_loss(\n",
    "        state.params,\n",
    "        qpos=dataset[\"qpos\"],\n",
    "        qvel=dataset[\"qvel\"],\n",
    "        ctrl_vec=dataset[\"qact\"],\n",
    "        qpos_des=dataset[\"qpos_next\"],\n",
    "    )\n",
    "    loss_hist.append(loss)\n",
    "    print(f\"Epoch {epoch:3d}, Loss: {loss:.6e}\")\n",
    "    \n",
    "    # Store parameter history\n",
    "    params_hist.append(state.params)\n",
    "    \n",
    "    # TRAIN - update parameters using batch\n",
    "    batch, indxs = get_batch(dataset, PARAMS.SEED, indxs, PARAMS.TRAIN.BATCH_SIZE)\n",
    "    state, grads = train_step(\n",
    "        state,\n",
    "        qpos=batch[\"qpos\"],\n",
    "        qvel=batch[\"qvel\"],\n",
    "        ctrl_vec=batch[\"qact\"],\n",
    "        qpos_des=batch[\"qpos_next\"],\n",
    "    )\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(\"\\nFinal optimized parameters:\")\n",
    "for param_name, values in state.params.items():\n",
    "    print(f\"{param_name}:\")\n",
    "    for i, (joint, val) in enumerate(zip(JOINT_NAMES, values)):\n",
    "        print(f\"  {joint}: {val:.6f}\")\n",
    "\n",
    "print(\"Training loop ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Uncomment when training is complete\n",
    "\n",
    "# baseline_loss = total_loss(\n",
    "#     zero_params,\n",
    "#     qpos=dataset[\"qpos\"],\n",
    "#     qvel=dataset[\"qvel\"],\n",
    "#     ctrl_vec=dataset[\"qact\"],\n",
    "#     qpos_des=dataset[\"qpos_next\"],\n",
    "# )\n",
    "# adjusted_model_loss = np.array(loss_hist)\n",
    "# base_line = np.ones_like(adjusted_model_loss)\n",
    "\n",
    "# print(f\"Baseline loss (no optimization): {baseline_loss:.6e}\")\n",
    "# print(f\"Final loss (optimized): {adjusted_model_loss[-1]:.6e}\")\n",
    "# print(f\"Improvement: {(1 - adjusted_model_loss[-1]/baseline_loss)*100:.2f}%\")\n",
    "\n",
    "print(\"Loss analysis ready. Uncomment when training is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Uncomment when training is complete\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os, joblib\n",
    "\n",
    "# # Create comprehensive visualization\n",
    "# fig = plt.figure(figsize=(16, 12))\n",
    "# gs = fig.add_gridspec(4, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# # 1. Loss convergence\n",
    "# ax1 = fig.add_subplot(gs[0, :])\n",
    "# ax1.plot(adjusted_model_loss / baseline_loss, label=\"Relative loss\", linewidth=2)\n",
    "# ax1.plot(base_line, '--', label=\"Baseline (no optimization)\", alpha=0.7)\n",
    "# ax1.set_title(\"Training Loss Convergence\", fontsize=14, fontweight='bold')\n",
    "# ax1.set_ylabel(\"Relative loss\")\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.legend()\n",
    "# ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# # 2-4. Parameter convergence for each parameter type\n",
    "# param_types = ['armature', 'frictionloss', 'damping']\n",
    "# for idx, param_type in enumerate(param_types):\n",
    "#     ax = fig.add_subplot(gs[1, idx])\n",
    "#     for i, joint in enumerate(JOINT_NAMES):\n",
    "#         values = [p[param_type][i] for p in params_hist]\n",
    "#         ax.plot(values, label=joint, alpha=0.7)\n",
    "#     ax.set_title(f\"{param_type.capitalize()} Convergence\")\n",
    "#     ax.set_ylabel(param_type)\n",
    "#     ax.set_xlabel(\"Epoch\")\n",
    "#     ax.legend(fontsize=8, loc='best')\n",
    "#     ax.grid(True, alpha=0.3)\n",
    "\n",
    "# # 5-7. Final parameter values by joint\n",
    "# for idx, param_type in enumerate(param_types):\n",
    "#     ax = fig.add_subplot(gs[2, idx])\n",
    "#     final_values = state.params[param_type]\n",
    "#     colors = plt.cm.viridis(np.linspace(0, 1, len(JOINT_NAMES)))\n",
    "#     bars = ax.bar(range(len(JOINT_NAMES)), final_values, color=colors)\n",
    "#     ax.set_title(f\"Final {param_type.capitalize()} Values\")\n",
    "#     ax.set_ylabel(param_type)\n",
    "#     ax.set_xticks(range(len(JOINT_NAMES)))\n",
    "#     ax.set_xticklabels(JOINT_NAMES, rotation=45, ha='right', fontsize=8)\n",
    "#     ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# # 8. Comparison table\n",
    "# ax_table = fig.add_subplot(gs[3, :])\n",
    "# ax_table.axis('off')\n",
    "# table_data = []\n",
    "# for i, joint in enumerate(JOINT_NAMES):\n",
    "#     row = [\n",
    "#         joint,\n",
    "#         f\"{state.params['armature'][i]:.4f}\",\n",
    "#         f\"{state.params['frictionloss'][i]:.4f}\",\n",
    "#         f\"{state.params['damping'][i]:.4f}\"\n",
    "#     ]\n",
    "#     table_data.append(row)\n",
    "\n",
    "# table = ax_table.table(\n",
    "#     cellText=table_data,\n",
    "#     colLabels=['Joint', 'Armature', 'Friction Loss', 'Damping'],\n",
    "#     cellLoc='center',\n",
    "#     loc='center',\n",
    "#     colWidths=[0.3, 0.2, 0.2, 0.2]\n",
    "# )\n",
    "# table.auto_set_font_size(False)\n",
    "# table.set_fontsize(9)\n",
    "# table.scale(1, 2)\n",
    "# for i in range(len(JOINT_NAMES) + 1):\n",
    "#     if i == 0:\n",
    "#         table[(i, 0)].set_facecolor('#40466e')\n",
    "#         table[(i, 1)].set_facecolor('#40466e')\n",
    "#         table[(i, 2)].set_facecolor('#40466e')\n",
    "#         table[(i, 3)].set_facecolor('#40466e')\n",
    "#         table[(i, 0)].set_text_props(weight='bold', color='white')\n",
    "#         table[(i, 1)].set_text_props(weight='bold', color='white')\n",
    "#         table[(i, 2)].set_text_props(weight='bold', color='white')\n",
    "#         table[(i, 3)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# # Save results\n",
    "# folder_path = os.path.join(\"assets/experiments\", PARAMS.EXPERIMENT_NAME)\n",
    "# os.makedirs(folder_path, exist_ok=True)\n",
    "# img_path = os.path.join(folder_path, \"pictures\")\n",
    "# os.makedirs(img_path, exist_ok=True)\n",
    "\n",
    "# # Save optimization results\n",
    "# joblib.dump(\n",
    "#     {\n",
    "#         \"params\": params_hist,\n",
    "#         \"final_params\": state.params,\n",
    "#         \"loss_hist\": adjusted_model_loss,\n",
    "#         \"baseline_loss\": baseline_loss,\n",
    "#         \"joint_names\": JOINT_NAMES,\n",
    "#         \"pid_gains\": PID_GAINS,\n",
    "#     },\n",
    "#     os.path.join(folder_path, \"exo_optimization_results.joblib\"),\n",
    "# )\n",
    "\n",
    "# # Save figure\n",
    "# fig.savefig(\n",
    "#     os.path.join(img_path, \"exo_optimization.png\"),\n",
    "#     format=\"png\",\n",
    "#     bbox_inches=\"tight\",\n",
    "#     dpi=300\n",
    "# )\n",
    "\n",
    "# print(f\"Results saved to {folder_path}\")\n",
    "# plt.show()\n",
    "\n",
    "print(\"Visualization code ready. Uncomment when training is complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
